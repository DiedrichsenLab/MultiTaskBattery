{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd093766081e3e487981e60414715c0b150df167d7ea13af2b95fe88c3a7300a465",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from math import ceil\n",
    "import copy\n",
    "# import cv2\n",
    "import glob\n",
    "import shutil\n",
    "import json\n",
    "from itertools import count\n",
    "from collections import OrderedDict\n",
    "\n",
    "import constants as consts\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeFiles:\n",
    "    \"\"\"\n",
    "    This class makes run and target files\n",
    "        Args:\n",
    "            block_names (list of str): options are 'visual_search', 'n_back', 'social_prediction', 'semantic_prediction', 'action_observation'\n",
    "            run_name_prefix (str): prefix of run name\n",
    "            tile_run (int): determines number of block repeats within a run\n",
    "            instruct_dur (int): length of instruct for block_names (sec)\n",
    "            block_dur_secs (int): length of block_name (sec)\n",
    "            rest_dur_secs (int): length of rest (sec), 0 if no rest\n",
    "            num_runs (int): number of runs\n",
    "            counterbalance_runs (bool): counterbalance block order across runs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        f = open(file=os.path.join(Defaults.CONFIG_DIR, 'run_config.json'))\n",
    "        config = json.load(f)\n",
    "        self.config = copy.deepcopy(config)\n",
    "        self.config.update(**kwargs)\n",
    "    \n",
    "    def _create_run_dataframe(self, target_files):\n",
    "        for iter, target_file in enumerate(target_files):\n",
    "            \n",
    "            # load target file\n",
    "            dataframe = pd.read_csv(target_file)\n",
    "\n",
    "            start_time = dataframe.iloc[0]['start_time'] + self.cum_time \n",
    "            end_time = dataframe.iloc[-1]['start_time'] + dataframe.iloc[-1]['trial_dur'] + self.config['instruct_dur'] + self.cum_time\n",
    "\n",
    "            target_file_name = Path(target_file).name\n",
    "            num_sec = re.findall(r'\\d+(?=sec)', target_file)[0]\n",
    "            target_num = re.findall(r'\\d+(?=.csv)', target_file)[0]\n",
    "            num_trials = len(dataframe)\n",
    "\n",
    "            data = {'block_name': self.block_name, 'block_iter': iter+1, 'block_num': self.block_num+1, # 'block_iter': iter+1\n",
    "                    'num_trials': num_trials, 'target_num': target_num, 'num_sec': num_sec,\n",
    "                    'target_file': target_file_name, 'start_time': start_time, 'end_time': end_time,\n",
    "                    'instruct_dur': self.config['instruct_dur'], 'display_trial_feedback': self.display_trial_feedback,\n",
    "                    'replace_stimuli': self.replace_stimuli, 'feedback_type': self.feedback_type, 'target_score': self.target_score}\n",
    "\n",
    "            self.all_data.append(data)\n",
    "            self.cum_time = end_time\n",
    "    \n",
    "    def _save_run_file(self, dataframe, run_name):\n",
    "        # save out to file\n",
    "        dataframe.to_csv(os.path.join(Defaults.RUN_DIR, run_name), index=False, header=True)\n",
    "    \n",
    "    def _add_rest(self):\n",
    "        run_name_prefix = self.config['run_name_prefix']\n",
    "        run_files = sorted(glob.glob(os.path.join(Defaults.RUN_DIR, f'*{run_name_prefix}*.csv')))\n",
    "\n",
    "        # make target file\n",
    "        BlockClass = TASK_MAP['rest']\n",
    "        config = self._load_config(fpath=os.path.join(Defaults.CONFIG_DIR, f'rest_config.json'))\n",
    "        block = BlockClass(target_config=config)\n",
    "        self.target_name = block.make_targetfile()\n",
    "\n",
    "        for run_file in run_files:\n",
    "            dataframe = pd.read_csv(run_file)\n",
    "\n",
    "            dataframe = self._add_rest_rows(dataframe)\n",
    "\n",
    "            dataframe.to_csv(run_file, index = False, header = True)\n",
    "    \n",
    "    def _counterbalance_runs(self):\n",
    "        while self._test_counterbalance() > 0:\n",
    "            print('not balanced ...')\n",
    "            self._create_run()\n",
    "        \n",
    "        print('these runs are perfectly balanced')\n",
    "    \n",
    "    def _check_task_run(self):\n",
    "        # check if task exists in dict\n",
    "        exists_in_dict = [True for key in self.target_dict.keys() if self.block_name==key]\n",
    "        if not exists_in_dict: \n",
    "            self.target_dict.update({self.block_name: self.fpaths})\n",
    "\n",
    "        # create run dataframe\n",
    "        random.seed(self.block_num+1)\n",
    "        target_files_sample = [self.target_dict[self.block_name].pop(random.randrange(len(self.target_dict[self.block_name]))) for _ in np.arange(self.config['tile_run'])]\n",
    "\n",
    "        return target_files_sample\n",
    "   \n",
    "    def _insert_row(self, row_number, dataframe, row_value): \n",
    "        # Slice the upper half of the dataframe \n",
    "        df1 = dataframe[0:row_number] \n",
    "    \n",
    "        # Store the result of lower half of the dataframe \n",
    "        df2 = dataframe[row_number:] \n",
    "    \n",
    "        # Insert the row in the upper half dataframe \n",
    "        df1.loc[row_number]=row_value \n",
    "    \n",
    "        # Concat the two dataframes \n",
    "        df_result = pd.concat([df1, df2]) \n",
    "    \n",
    "        # Reassign the index labels \n",
    "        df_result.index = [*range(df_result.shape[0])] \n",
    "    \n",
    "        # Return the updated dataframe \n",
    "        return df_result \n",
    "    \n",
    "    def _correct_start_end_times(self, dataframe):\n",
    "\n",
    "        timestamps = (np.cumsum(dataframe['num_sec'] + dataframe['instruct_dur'])).to_list()\n",
    "\n",
    "        dataframe['end_time'] = timestamps\n",
    "\n",
    "        timestamps.insert(0, 0) \n",
    "        dataframe['start_time'] = timestamps[:-1]\n",
    "\n",
    "        return dataframe \n",
    "    \n",
    "    def _add_rest_rows(self, dataframe):\n",
    "        self.num_rest = (len(self.config['block_names']) * self.config['tile_run']) - 1\n",
    "        \n",
    "        trials_before_rest = np.tile(np.round((len(dataframe) + self.num_rest) /(self.num_rest)), self.num_rest)\n",
    "        rest = np.cumsum(trials_before_rest).astype(int) - 1\n",
    "\n",
    "        # row values\n",
    "        row_dict = {'block_name': 'rest', 'block_iter': np.float('NaN') , 'block_num': len(self.config['block_names']) + 1,\n",
    "                     'num_trials': 1, 'target_num': np.float('NaN') , 'num_sec': self.config['rest_dur_secs'],\n",
    "                    'target_file': self.target_name, 'start_time': np.float('NaN') , 'end_time': np.float('NaN') ,\n",
    "                    'instruct_dur': 0, 'display_trial_feedback': np.float('NaN') ,\n",
    "                    'replace_stimuli': np.float('NaN') , 'feedback_type': np.float('NaN') , 'target_score': np.float('NaN') }\n",
    "\n",
    "        rest_blocks = np.arange(1, self.num_rest+1)\n",
    "\n",
    "        # Let's create a row which we want to insert \n",
    "        for idx, row_number in enumerate(rest):\n",
    "            # row_value = np.tile('rest', len(dataframe.columns))\n",
    "            row_dict.update({'block_iter': rest_blocks[idx]})\n",
    "            row_value = list(row_dict.values())\n",
    "            if row_number > dataframe.index.max()+1: \n",
    "                print(\"Invalid row_number\") \n",
    "            else: \n",
    "                dataframe = self._insert_row(row_number, dataframe, row_value)\n",
    "\n",
    "        # update start and end times\n",
    "        dataframe = self._correct_start_end_times(dataframe)\n",
    "\n",
    "        return dataframe\n",
    "    \n",
    "    def _load_config(self, fpath):\n",
    "        \"\"\" loads JSON file as dict\n",
    "            Args: \n",
    "                fpath (str): full path to .json file\n",
    "            Returns\n",
    "                loads JSON as dict\n",
    "        \"\"\"\n",
    "        f = open(fpath) \n",
    "    \n",
    "        # returns JSON object as a dict \n",
    "        return json.load(f) \n",
    "    \n",
    "    def _save_target_files(self, df_target):\n",
    "        \"\"\" saves out target files\n",
    "            Args:\n",
    "                df_target (pandas dataframe)\n",
    "            Returns:\n",
    "                modified pandas dataframes `df_target`\n",
    "        \"\"\"\n",
    "        # # shuffle and set a seed (to ensure reproducibility)\n",
    "        # df_target = df_target.sample(n=len(df_target), random_state=self.random_state, replace=False).reset_index(drop=True)\n",
    "\n",
    "        start_time = np.round(np.arange(0, self.num_trials*(self.config['trial_dur']+self.config['iti_dur']), self.config['trial_dur']+self.config['iti_dur']), 1)\n",
    "        data = {\"trial_dur\":self.config['trial_dur'], \"iti_dur\":self.config['iti_dur'], \"start_time\":start_time, \"hand\": self.config['hand']}\n",
    "\n",
    "        df_target = pd.concat([df_target, pd.DataFrame.from_records(data)], axis=1, ignore_index=False, sort=False)\n",
    "\n",
    "        # get targetfile name\n",
    "        tf_name = f\"{self.config['block_name']}_{self.config['block_dur_secs']}sec\" # was {self.num_trials}trials\n",
    "        tf_name = self._get_target_file_name(tf_name)\n",
    "\n",
    "        # save out dataframe to a csv file in the target directory (TARGET_DIR)\n",
    "        df_target.to_csv(os.path.join(self.TARGET_DIR, tf_name), index=False, header=True)\n",
    "\n",
    "        print(f'saving out {tf_name}')\n",
    "    \n",
    "    def _get_target_file_name(self, targetfile_name):\n",
    "        # figure out naming convention for target files\n",
    "        target_num = []\n",
    "\n",
    "        if not os.path.exists(self.TARGET_DIR):\n",
    "            os.makedirs(self.TARGET_DIR)\n",
    "            \n",
    "        for f in os.listdir(self.TARGET_DIR):\n",
    "            if re.search(targetfile_name, f):\n",
    "                regex = r\"_(\\d+).csv\"\n",
    "                target_num.append(int(re.findall(regex, f)[0]))\n",
    "                \n",
    "        if target_num==[]:\n",
    "            outfile_name = f\"{targetfile_name}_01.csv\" # first target file\n",
    "        else:\n",
    "            num = np.max(target_num)+1\n",
    "            outfile_name = f\"{targetfile_name}_{num:02d}.csv\" # second or more\n",
    "        \n",
    "        return outfile_name\n",
    "    \n",
    "    def _sample_evenly_from_col(self, dataframe, num_stim, column='condition_name', **kwargs):\n",
    "        if kwargs.get('random_state'):\n",
    "            random_state = kwargs['random_state']\n",
    "        else:\n",
    "            random_state = 2\n",
    "\n",
    "        if kwargs.get('replace'):\n",
    "            replace = kwargs['replace']\n",
    "        else:\n",
    "            replace = False\n",
    "        num_values = len(dataframe[column].unique())\n",
    "        group_size = int(np.ceil(num_stim / num_values))\n",
    "        group_data = dataframe.groupby(column).apply(lambda x: x.sample(group_size, random_state=random_state, replace=replace))\n",
    "        group_data = group_data.sample(num_stim, random_state=random_state, replace=replace).reset_index(drop=True).sort_values(column)\n",
    "        return group_data.reset_index(drop=True)\n",
    "    \n",
    "    def _correct_block_iter(self, dataframe):\n",
    "        dataframe['block_iter'] = dataframe.groupby('block_name').cumcount() + 1 \n",
    "\n",
    "        return dataframe\n",
    "    \n",
    "    def _create_run(self):\n",
    "        # delete any run files that exist in the folder\n",
    "        # files = glob.glob(os.path.join(Defaults.RUN_DIR, '*run*.csv'))\n",
    "        # for f in files:\n",
    "        #     os.remove(f)\n",
    "\n",
    "        # create run files\n",
    "        self.target_dict = {}\n",
    "        for run in np.arange(self.config['num_runs']):\n",
    "            self.cum_time = 0.0\n",
    "            self.all_data = []\n",
    "\n",
    "            for self.block_num, self.block_name in enumerate(self.config['block_names']):\n",
    "\n",
    "                # get target files for `block_name`\n",
    "                self.TARGET_DIR = os.path.join(Defaults.TARGET_DIR, self.block_name)\n",
    "                self.fpaths = sorted(glob.glob(os.path.join(self.TARGET_DIR, f'*{self.block_name}*.csv')))\n",
    "\n",
    "                # sample tasks\n",
    "                target_files_sample = self._check_task_run()\n",
    "\n",
    "                # get tf info\n",
    "                df = pd.read_csv(os.path.join(self.TARGET_DIR, target_files_sample[0]))\n",
    "                self.display_trial_feedback = np.unique(df['display_trial_feedback'])[0]\n",
    "                self.replace_stimuli = np.unique(df['replace_stimuli'])[0]\n",
    "                self.feedback_type = np.unique(df['feedback_type'])[0]\n",
    "                self.target_score = np.unique(df['target_score'])[0]\n",
    "\n",
    "                # create run dataframe\n",
    "                self._create_run_dataframe(target_files=target_files_sample)\n",
    "\n",
    "            # shuffle order of tasks within run\n",
    "            df_run = pd.DataFrame.from_dict(self.all_data)\n",
    "            df_run = df_run.sample(n=len(df_run), replace=False)\n",
    "\n",
    "            # correct `block_iter`, `start_time`, `run_time`\n",
    "            df_run = self._correct_block_iter(dataframe=df_run)\n",
    "            df_run['start_time'] = sorted(df_run['start_time']) \n",
    "            df_run['end_time'] = sorted(df_run['end_time']) \n",
    "\n",
    "            # save run file\n",
    "            run_name = self.config['run_name_prefix'] + '_' +  f'{run+1:02d}' + '.csv'\n",
    "            self._save_run_file(dataframe=df_run, run_name=run_name)\n",
    "            # print(f'saving out {run_name}')\n",
    "    \n",
    "    def _test_counterbalance(self):\n",
    "        filenames = sorted(glob.glob(os.path.join(Defaults.RUN_DIR, '*run_*')))\n",
    "\n",
    "        dataframe_all = pd.DataFrame()\n",
    "        for i, file in enumerate(filenames):\n",
    "            dataframe = pd.read_csv(file)\n",
    "            dataframe['run'] = i + 1\n",
    "            dataframe['block_num_unique'] = np.arange(len(dataframe)) + 1\n",
    "            dataframe_all = pd.concat([dataframe_all, dataframe])\n",
    "\n",
    "        # create new column\n",
    "        dataframe_all['block_name_unique'] = dataframe_all['block_name'] + '_' + dataframe_all['block_iter'].astype(str)\n",
    "\n",
    "        task = np.array(list(map({}.setdefault, dataframe_all['block_name_unique'], count()))) + 1\n",
    "        last_task = list(task[0:-1])\n",
    "        last_task.insert(0,0)\n",
    "        last_task = np.array(last_task)\n",
    "        last_task[dataframe_all['block_num_unique']==1] = 0\n",
    "\n",
    "        dataframe_all['last_task'] = last_task\n",
    "        dataframe_all['task'] = task\n",
    "        dataframe_all['task_num'] = task\n",
    "\n",
    "        # get pivot table\n",
    "        f = pd.pivot_table(dataframe_all, index=['task'], columns=['last_task'], values=['task_num'], aggfunc=len)\n",
    "\n",
    "        return sum([sum(f['task_num'][col]>5) for col in f['task_num'].columns]) \n",
    "    \n",
    "    def check_videos(self):\n",
    "        for block_name in ['action_observation', 'social_prediction']:\n",
    "\n",
    "            TARGET_DIR = os.path.join(Defaults.TARGET_DIR, block_name)\n",
    "\n",
    "            files = glob.glob(os.path.join(Defaults.TARGET_DIR, block_name, '*.csv'))\n",
    "\n",
    "            # loop over files\n",
    "            video_count = []\n",
    "            for file in files:\n",
    "                dataframe = pd.read_csv(file)\n",
    "\n",
    "                # loop over videos and check that they exist\n",
    "                videos = dataframe['stim']\n",
    "                for stim in videos:\n",
    "                    video_fpath = os.path.join(Defaults.STIM_DIR, block_name, \"modified_clips\", stim)\n",
    "                    if not os.path.exists(video_fpath):\n",
    "                        video_count.append(stim)\n",
    "                        print(f'{block_name}: {stim} is missing from videos')\n",
    "\n",
    "            if not video_count:\n",
    "                print(f'there are no videos missing for {block_name}')\n",
    "    \n",
    "    def make_targetfiles(self, **kwargs):\n",
    "        for self.block_name in self.config['block_names']:\n",
    "\n",
    "            TARGET_DIR = os.path.join(Defaults.TARGET_DIR, self.block_name)\n",
    "\n",
    "            # delete any target files that exist in the folder\n",
    "            files = glob.glob(os.path.join(Defaults.TARGET_DIR, self.block_name, '*.csv'))\n",
    "            for f in files:\n",
    "                os.remove(f)\n",
    "\n",
    "            # make target files\n",
    "            BlockClass = TASK_MAP[self.block_name]\n",
    "            config = self._load_config(fpath=os.path.join(Defaults.CONFIG_DIR, f'{self.block_name}_config.json'))\n",
    "            block = BlockClass(target_config=config, **kwargs)\n",
    "            block.make_targetfile()\n",
    "    \n",
    "    def make_runfiles(self, **kwargs):\n",
    "        \n",
    "        # make run files\n",
    "        self._create_run()\n",
    "\n",
    "        # OPTION TO COUNTERBALANCE RUNS\n",
    "        if self.config['counterbalance_runs']:\n",
    "            self._counterbalance_runs()\n",
    "\n",
    "        # OPTION TO ADD REST\n",
    "        if self.config['rest_dur_secs']>0:\n",
    "            self._add_rest()\n",
    "\n",
    "        # check if videos for action observation and social prediction exist\n",
    "        self.check_videos()\n",
    "    \n",
    "    def make_all(self, **kwargs):\n",
    "        # create target files\n",
    "        self.make_targetfiles(**kwargs)\n",
    "\n",
    "        # create run files\n",
    "        self.make_runfiles(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualSearch(MakeFiles):\n",
    "    \"\"\"\n",
    "        This class makes target files for Visual Search using parameters from config file\n",
    "        Args:\n",
    "            target_config (dict): dictionary loaded from `visual_search_config.json`\n",
    "        Kwargs:\n",
    "            block_name (str): 'visual_search'\n",
    "            orientations (int): orientations of target/distractor stims\n",
    "            balance_blocks (dict): keys are 'condition_name', 'trial_type'\n",
    "            trial_dur (int): length of trial (sec)\n",
    "            iti_dur (iti): length of iti (sec)\n",
    "            instruct_dur (int): length of instruct for block_names (sec)\n",
    "            hand (str): response hand\n",
    "            replace (bool): sample stim with or without replacement\n",
    "            display_trial_feedback (bool): display trial-by-trial feedback\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_config, **kwargs):\n",
    "        super().__init__()\n",
    "        self.config.update(target_config)\n",
    "        self.config.update(**kwargs)\n",
    "    \n",
    "    def _get_block_info(self):\n",
    "        # num of blocks (i.e. target files) to make\n",
    "        self.num_blocks = self.config['num_runs'] * self.config['tile_run']\n",
    "\n",
    "        # get overall number of trials\n",
    "        self.num_trials = int(self.config['block_dur_secs'] / (self.config['trial_dur'] + self.config['iti_dur']))  \n",
    "\n",
    "        # get `num_stims` - lowest denominator across `balance_blocks`\n",
    "        denominator = np.prod([len(stim) for stim in [*self.config['balance_blocks'].values()]])\n",
    "        self.num_stims = ceil(self.num_trials / denominator) # round up to nearest int\n",
    "    \n",
    "    def _create_columns(self):\n",
    "\n",
    "        def _get_condition(x):\n",
    "            for key in self.config['balance_blocks']['condition_name'].keys():\n",
    "                cond = self.config['balance_blocks']['condition_name'][key]\n",
    "                if x==cond:\n",
    "                    value = key\n",
    "            return value\n",
    "\n",
    "        dataframe = pd.DataFrame()\n",
    "        # make `condition_name` column\n",
    "        conds = [self.config['balance_blocks']['condition_name'][key] for key in self.config['balance_blocks']['condition_name'].keys()]\n",
    "        dataframe['stim'] = self.num_trials*conds\n",
    "        dataframe['condition_name'] = dataframe['stim'].apply(lambda x: _get_condition(x))\n",
    "        dataframe['stim'] = dataframe['stim'].astype(int)\n",
    "\n",
    "        # make `trial_type` column\n",
    "        dataframe['trial_type'] = self.num_trials*self.config['balance_blocks']['trial_type']\n",
    "        dataframe['trial_type'] = dataframe['trial_type'].sort_values().reset_index(drop=True)\n",
    "\n",
    "        dataframe['display_trial_feedback'] = self.config['display_trial_feedback']\n",
    "        dataframe['replace_stimuli'] = self.config['replace']\n",
    "        dataframe['feedback_type'] = self.config['feedback_type']\n",
    "        dataframe['target_score'] = self.config['target_score']\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    def _balance_design(self, dataframe):\n",
    "        \n",
    "        # this assumes that there is a `condition_name` key in all tasks (which there should be)\n",
    "        # dataframe = dataframe.groupby([*self.config['balance_blocks']], as_index=False).apply(lambda x: self._sample_evenly_from_col(x, num_stim=self.num_stims, column='condition_name', random_state=self.random_state, replace=self.config['replace'])).reset_index(drop=True)\n",
    "\n",
    "        dataframe =  dataframe.groupby([*self.config['balance_blocks']], as_index=False).apply(lambda x: x.sample(n=self.num_stims, random_state=self.random_state, replace=self.config['replace'])).reset_index(drop=True)\n",
    "        \n",
    "        # ensure that only `num_trials` are sampled\n",
    "        num_stims = int(self.num_trials / len(self.config['balance_blocks']['condition_name']))\n",
    "        dataframe = dataframe.groupby('condition_name', as_index=False).apply(lambda x: x.sample(n=num_stims, random_state=self.random_state, replace=False)).reset_index(drop=True)\n",
    "        \n",
    "        # shuffle the order of the trials\n",
    "        dataframe = dataframe.apply(lambda x: x.sample(n=self.num_trials, random_state=self.random_state, replace=False)).reset_index(drop=True)\n",
    "\n",
    "        # ensure that only `num_trials` are sampled\n",
    "        return dataframe\n",
    "\n",
    "    def _save_visual_display(self, dataframe):\n",
    "        # add visual display cols\n",
    "        display_pos, orientations_correct = zip(*[self._make_search_display(cond, self.config['orientations'], trial_type) for (cond, trial_type) in zip(dataframe[\"stim\"], dataframe[\"trial_type\"])])\n",
    "\n",
    "        data_dicts = []\n",
    "        for trial_idx, trial_conditions in enumerate(display_pos):\n",
    "            for condition, point in trial_conditions.items():\n",
    "                data_dicts.append({'trial': trial_idx, 'stim': condition, 'xpos': point[0], 'ypos': point[1], 'orientation': orientations_correct[trial_idx][condition]})  \n",
    "        \n",
    "        # save out to dataframe\n",
    "        df_display = pd.DataFrame.from_records(data_dicts)\n",
    "\n",
    "        # save out visual display\n",
    "        visual_display_name = self._get_visual_display_name()\n",
    "        df_display.to_csv(os.path.join(self.TARGET_DIR, visual_display_name))\n",
    "\n",
    "    def _get_visual_display_name(self):\n",
    "        block_name = self.config['block_name']\n",
    "        block_dur_secs = self.config['block_dur_secs']\n",
    "        tf_name = f\"{block_name}_{block_dur_secs}sec\"\n",
    "        tf_name = self._get_target_file_name(tf_name)\n",
    "\n",
    "        str_part = tf_name.partition(self.config['block_name'])\n",
    "        visual_display_name = 'display_pos' + str_part[2] \n",
    "\n",
    "        return visual_display_name\n",
    "    \n",
    "    def _make_search_display(self, display_size, orientations, trial_type):\n",
    "        # make location and orientations lists (for target and distractor items)\n",
    "\n",
    "        # STIM POSITIONS\n",
    "        grid_h_dva = 8.4\n",
    "        grid_v_dva = 11.7\n",
    "\n",
    "        n_h_items = 6\n",
    "        n_v_items = 8\n",
    "\n",
    "        item_h_pos = np.linspace(-grid_h_dva / 2.0, +grid_h_dva/ 2.0, n_h_items)\n",
    "        item_v_pos = np.linspace(-grid_v_dva / 2.0, +grid_v_dva / 2.0, n_v_items)\n",
    "\n",
    "        grid_pos = []\n",
    "        for curr_h_pos in item_h_pos:\n",
    "            for curr_v_pos in item_v_pos:\n",
    "                grid_pos.append([curr_h_pos, curr_v_pos])\n",
    "\n",
    "        locations = random.sample(grid_pos, display_size)\n",
    "\n",
    "        ## STIM ORIENTATIONS\n",
    "        orientations_list = orientations*int(display_size/4)\n",
    "        \n",
    "        # if trial type is false - randomly replace target stim (90)\n",
    "        # with a distractor\n",
    "        if not trial_type:\n",
    "            orientations_list = [random.sample(orientations[1:],1)[0] if x==90 else x for x in orientations_list]\n",
    "        \n",
    "        # if trial is true and larger than 4, leave one target stim (90) in list \n",
    "        # and randomly replace the others with distractor stims\n",
    "        if display_size >4 and trial_type:\n",
    "            indices = [i for i, x in enumerate(orientations_list) if x == 90]\n",
    "            indices.pop(0)\n",
    "            new_num = random.sample(orientations[1:],2) # always assumes that orientations_list is as follows: [90,180,270,360]\n",
    "            for i, n in zip(*(indices, new_num)): \n",
    "                orientations_list[i] = n\n",
    "\n",
    "        return dict(enumerate(locations)), dict(enumerate(orientations_list))\n",
    "        \n",
    "    def make_targetfile(self):\n",
    "        \"\"\"\n",
    "        makes target file(s) for action observation\n",
    "        \"\"\"\n",
    "        # get info about block\n",
    "        self._get_block_info()\n",
    "\n",
    "        seeds = np.arange(self.num_blocks)+1\n",
    "\n",
    "        for self.block in np.arange(self.num_blocks):\n",
    "\n",
    "            # randomly sample so that conditions (2Back- and 2Back+) are equally represented\n",
    "            self.random_state = seeds[self.block]\n",
    "\n",
    "            # create the dataframe\n",
    "            df_target = self._create_columns()\n",
    "\n",
    "            # balance the dataframe\n",
    "            df_target = self._balance_design(dataframe=df_target)\n",
    "\n",
    "            self.TARGET_DIR = os.path.join(Defaults.TARGET_DIR, self.config['block_name'])\n",
    "\n",
    "            # save visual display dataframe\n",
    "            self._save_visual_display(dataframe=df_target)\n",
    "\n",
    "            # save target file\n",
    "            self._save_target_files(df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Target():\n",
    "\n",
    "    def __init__(self, study_name, task_name, hand, trial_dur, iti_dur,\n",
    "                 run_number, display_trial_feedback = True, task_dur = 30, tr = 1):\n",
    "\n",
    "        \"\"\"\n",
    "        variables and information shared across all tasks\n",
    "        \"\"\"\n",
    "        self.study_name             = study_name             # name of the study: 'fmri' or 'behavioral'\n",
    "        self.task_name              = task_name              # name of the task\n",
    "        self.task_dur               = task_dur               # duration of the task (default: 30 sec)\n",
    "        self.hand                   = hand                   # string representing the hand: \"right\", \"left\", or \"none\"\n",
    "        self.trial_dur              = trial_dur              # duration of trial\n",
    "        self.iti_dur                = iti_dur                # duration of the inter trial interval\n",
    "        self.display_trial_feedback = display_trial_feedback # display feedback after trial (default: True)\n",
    "        self.tr                     = tr                     # the TR of the scanner\n",
    "        self.run_number             = run_number             # the number of run\n",
    "        self.target_dict            = {}                     # a dicttionary that will be saved as target file for the task\n",
    "         \n",
    "    def make_trials(self):\n",
    "        \"\"\"\n",
    "        making trials (rows) with columns (variables) shared across tasks\n",
    "        \"\"\"\n",
    "        self.num_trials = int(self.task_dur/(self.trial_dur + self.iti_dur)) # total number of trials\n",
    "        self.target_dict['start_time'] = [(self.trial_dur + self.iti_dur)*trial_number for trial_number in range(self.num_trials)]\n",
    "        self.target_dict['end_time']   = [(trial_number+1)*self.trial_dur + trial_number*self.iti_dur for trial_number in range(self.num_trials)]\n",
    "        self.target_dict['hand']       = np.tile(self.hand, self.num_trials).T.flatten() \n",
    "        self.target_dict['trial_dur']  = [self.trial_dur for trial_number in range(self.num_trials)]\n",
    "        self.target_dict['iti_dur']    = [self.iti_dur for trial_number in range(self.num_trials)]\n",
    "\n",
    "    def balance_design(self, dataframe):\n",
    "        \"\"\"\n",
    "        balance task design\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def save_target_file(self):\n",
    "        \"\"\"\n",
    "        save the target file in the corresponding directory\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = pd.DataFrame(self.target_dict)\n",
    "        # path to save the target files\n",
    "        path2task_target = consts.target_dir / self.study_name / self.task_name\n",
    "        consts.dircheck(path2task_target)\n",
    "\n",
    "        target_filename = path2task_target / f\"{self.task_name}_{self.task_dur}sec_{self.run_number+1:02d}.csv\"\n",
    "        self.df.to_csv(target_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualSearch(Target):\n",
    "    def __init__(self, study_name = 'behavioral', hand = 'right', \n",
    "                 trial_dur = 2, iti_dur = 0.5, run_number = 1, display_trial_feedback = True, \n",
    "                 task_dur = 30, tr = 1, tile_block = 1, block_dur_secs = 15, \n",
    "                 num_blocks = 5, replace = False):\n",
    "\n",
    "        super(VisualSearch, self).__init__(study_name = study_name, task_name = 'visual_search', hand = hand, \n",
    "                                           trial_dur = trial_dur, iti_dur = iti_dur, run_number = run_number, \n",
    "                                           display_trial_feedback = display_trial_feedback, task_dur = task_dur,\n",
    "                                           tr = tr)\n",
    "\n",
    "        self.block_dur_secs = block_dur_secs\n",
    "        self.num_blocks     = num_blocks\n",
    "        self.tile_block     = tile_block\n",
    "        # self.instruct_dur = 5\n",
    "        # self.replace = False\n",
    "        self.orientations   = list([90, 180, 270, 360])\n",
    "        self.trials_info = {'condition_name': {'easy': '4', 'hard': '8'}, 'trial_type': [True, False]}\n",
    "\n",
    "        self.num_blocks = self.num_blocks * self.tile_block\n",
    "        \n",
    "    def _add_task_info(self):\n",
    "        super.make_trials() # first fill in the common fields\n",
    "\n",
    "        # get overall number of trials\n",
    "        self.num_trials = int(self.block_dur_secs / (self.trial_dur + self.iti_dur))  \n",
    "\n",
    "        # get `num_stims` - lowest denominator across `balance_blocks`\n",
    "        denominator    = np.prod([len(stim) for stim in [*self.trials_info.values()]])\n",
    "        self.num_stims = np.ceil(self.num_trials / denominator) # round up to nearest int\n",
    "\n",
    "        conds = [self.trials_info['condition_name'][key] for key in self.trials_info['condition_name'].keys()]\n",
    "\n",
    "        self.target_dict['stim']    = (self.self.num_trials*conds).astype(int)\n",
    "        self.target_dict['condition_name'] = self.target_dict['stim'].apply(lambda x: _get_condition(x)) # get condifion??????\n",
    "\n",
    "        # make `trial_type` column\n",
    "        self.target_dict['trial_type'] = self.num_trials*self.balance_blocks['trial_type']\n",
    "        self.target_dict['trial_type'] = self.target_dict['trial_type'].sort_values().reset_index(drop=True)\n",
    "\n",
    "\n",
    "        seeds = np.arange(self.num_blocks)+1\n",
    "\n",
    "        for self.block in np.arange(self.num_blocks):\n",
    "            # randomly sample so that conditions are equally represented\n",
    "            self.random_state = seeds[self.block]\n",
    "       \n",
    "    def _save_visual_display(self, dataframe):\n",
    "        # add visual display cols\n",
    "        display_pos, orientations_correct = zip(*[self._make_search_display(cond, self.orientations, trial_type) for (cond, trial_type) in zip(dataframe[\"stim\"], dataframe[\"trial_type\"])])\n",
    "\n",
    "        data_dicts = []\n",
    "        for trial_idx, trial_conditions in enumerate(display_pos):\n",
    "            for condition, point in trial_conditions.items():\n",
    "                data_dicts.append({'trial': trial_idx, 'stim': condition, 'xpos': point[0], 'ypos': point[1], 'orientation': orientations_correct[trial_idx][condition]})  \n",
    "        \n",
    "        # save out to dataframe\n",
    "        df_display = pd.DataFrame.from_records(data_dicts)\n",
    "\n",
    "        # save out visual display\n",
    "        visual_display_name = self._get_visual_display_name()\n",
    "        df_display.to_csv(os.path.join(self.target_dir, visual_display_name))\n",
    "\n",
    "    def _make_search_display(self, display_size, orientations, trial_type):\n",
    "        # make location and orientations lists (for target and distractor items)\n",
    "\n",
    "        # STIM POSITIONS\n",
    "        grid_h_dva = 8.4\n",
    "        grid_v_dva = 11.7\n",
    "\n",
    "        n_h_items = 6\n",
    "        n_v_items = 8\n",
    "\n",
    "        item_h_pos = np.linspace(-grid_h_dva / 2.0, +grid_h_dva/ 2.0, n_h_items)\n",
    "        item_v_pos = np.linspace(-grid_v_dva / 2.0, +grid_v_dva / 2.0, n_v_items)\n",
    "\n",
    "        grid_pos = []\n",
    "        for curr_h_pos in item_h_pos:\n",
    "            for curr_v_pos in item_v_pos:\n",
    "                grid_pos.append([curr_h_pos, curr_v_pos])\n",
    "\n",
    "        locations = np.random.sample(grid_pos, display_size)\n",
    "\n",
    "        ## STIM ORIENTATIONS\n",
    "        orientations_list = orientations*int(display_size/4)\n",
    "        \n",
    "        # if trial type is false - randomly replace target stim (90)\n",
    "        # with a distractor\n",
    "        if not trial_type:\n",
    "            orientations_list = [np.random.sample(orientations[1:],1)[0] if x==90 else x for x in orientations_list]\n",
    "        \n",
    "        # if trial is true and larger than 4, leave one target stim (90) in list \n",
    "        # and randomly replace the others with distractor stims\n",
    "        if display_size >4 and trial_type:\n",
    "            indices = [i for i, x in enumerate(orientations_list) if x == 90]\n",
    "            indices.pop(0)\n",
    "            new_num = np.random.sample(orientations[1:],2) # always assumes that orientations_list is as follows: [90,180,270,360]\n",
    "            for i, n in zip(*(indices, new_num)): \n",
    "                orientations_list[i] = n\n",
    "\n",
    "        return dict(enumerate(locations)), dict(enumerate(orientations_list))\n",
    "\n",
    "    def _balance_design(self, dataframe):\n",
    "        \n",
    "        # this assumes that there is a `condition_name` key in all tasks (which there should be)\n",
    "        # dataframe = dataframe.groupby([*self.config['balance_blocks']], as_index=False).apply(lambda x: self._sample_evenly_from_col(x, num_stim=self.num_stims, column='condition_name', random_state=self.random_state, replace=self.config['replace'])).reset_index(drop=True)\n",
    "        self.df = pd.DataFrame(self.target_dict)\n",
    "        self.df =  self.df.groupby([*self.config['balance_blocks']], as_index=False).apply(lambda x: x.sample(n=self.num_stims, random_state=self.random_state, replace=self.config['replace'])).reset_index(drop=True)\n",
    "        \n",
    "        # ensure that only `num_trials` are sampled\n",
    "        num_stims = int(self.num_trials / len(self.config['balance_blocks']['condition_name']))\n",
    "        self.df = self.df.groupby('condition_name', as_index=False).apply(lambda x: x.sample(n=num_stims, random_state=self.random_state, replace=False)).reset_index(drop=True)\n",
    "        \n",
    "        # shuffle the order of the trials\n",
    "        self.df = self.df.apply(lambda x: x.sample(n=self.num_trials, random_state=self.random_state, replace=False)).reset_index(drop=True)\n",
    "\n",
    "        # ensure that only `num_trials` are sampled\n",
    "        # return dataframe"
   ]
  }
 ]
}